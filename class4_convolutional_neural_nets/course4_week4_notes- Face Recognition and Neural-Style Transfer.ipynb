{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition \n",
    "\n",
    "#### What is face recognition? \n",
    "\n",
    "* Face verification vs. face recognition \n",
    "   * Verification - given an image and name/ID, output whether the image is the claimed person \n",
    "   * Recognition - given you have $K$ persons in a database and their respective names/IDs, when you get an input image, output ID if image is any of the $K$ persons (or \"not recognized\")\n",
    "   \n",
    "#### One Shot Learning \n",
    "\n",
    "* One-shot learning - recognize that person given just one image of that person's face\n",
    "    * aka learn from just **one** example \n",
    "    * to make it work, we learn a \"similarity\" function \n",
    "        * $d($img1, img2$)$ $=$ degree of difference between images\n",
    "            * If $d($img1,img2$) \\leq \\tau \\rightarrow$ \"same\" else \"different\"\n",
    "            * pairwise comparison between the input image and each of the $K$ persons in the database\n",
    "            \n",
    "#### Siamese Network \n",
    "\n",
    "* Taigman et. al., 2014. DeepFace closing the gap to human level performance\n",
    "* Siamese Network - running two **identical CNNs** on two different inputs \n",
    "* Siamese Network explained: Suppose you have images $x^{(1)}$ and $x^{(2)} $ such that\n",
    "    * $x^{(1)} \\rightarrow$ ConvNet until last FC layer $\\rightarrow f(x^{(1)}) =$ \"encoding of $x^{(1)}$\"\n",
    "    * $x^{(2)} \\rightarrow$ ConvNet until last FC layer $\\rightarrow f(x^{(2)}) =$ \"encoding of $x^{(2)}$\"\n",
    "    * Then, we can define $d(x^{(1)}, x^{(2)}) = \\Vert {f(x^{(1)}) -  f(x^{(2)})}\\Vert^2_2$ such that:\n",
    "        * $\\Vert {f(x^{(i)}) -  f(x^{(j)})}\\Vert^2_2$ is small if $x^{(i)}$ and  $x^{(j)}$ are the same person \n",
    "        * $\\Vert {f(x^{(i)}) -  f(x^{(j)})}\\Vert^2_2$ is large if $x^{(i)}$ and  $x^{(j)}$ are different people \n",
    "            * Use backprop until all these conditions are satisfied\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            \n",
    "#### Triplet Loss \n",
    "\n",
    "* Schroff et al. 2015, FaceNet: A unified embedding for face recognition and clustering \n",
    "* One way to learn parameters to get a good encoding for faces is to define and apply gradient descent on triplet loss function\n",
    "* Suppose $A$ = anchor image, $P$ = positive (same person), $N$ = negative (different person)\n",
    "    * Want $\\Vert f(A) - f(P)\\Vert^2 \\leq \\Vert f(A) - f(N)\\Vert^2$ \n",
    "        * Trivial solution workaround since $\\Vert f(A) - f(P)\\Vert^2 - \\Vert f(A) - f(N)\\Vert^2 \\leq 0 $ you can just make everything zero, so we add a margin $\\alpha$ such that:\n",
    "           *  $\\Vert f(A) - f(P)\\Vert^2 - \\Vert f(A) - f(N)\\Vert^2 + \\alpha \\leq 0 $\n",
    "        * Thus, we have $\\Vert f(A) - f(P)\\Vert^2 + \\alpha \\leq \\Vert f(A) - f(N)\\Vert^2$\n",
    "        \n",
    "* Triplet loss function: Given 3 images $A, P, N$:\n",
    "    * Define $ L(A,P,N) = \\max(\\Vert f(A) - f(P)\\Vert^2 - \\Vert f(A) - f(N)\\Vert^2 + \\alpha, 0)$\n",
    "    * Thus, overall cost is $J = \\sum\\limits_{i=1}^{m}{L(A^{(i)},P^{(i)},N^{(i)})}$\n",
    "    * Training set can be: 10k pictures of 1k people with some pairs $A$ and $P$ of the same person \n",
    "        * During training, if $A,P,N$ are chosen randomly, then  $d(A,P) + \\alpha \\leq d(A,N)$ is easily satisfied\n",
    "        * So, choose triplets that are \"hard\" to train on s.t.:\n",
    "            * $d(A,P) \\approx d(A,N)$ so that the model has to train \"extra hard\" so that there is at least a margin $\\alpha$ between a positive and negative differential \n",
    "        * use gradient descent to minimize the cost as per usual \n",
    "* some companies used 100millions of images, just get the parameters they trained \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Face Verification and Binary Classification\n",
    "\n",
    "* Have a siamese NN and have two encodings $f(x^{(i)})$ feed into a logistic regression unit to make a prediction $\\hat{y}$ where $\\hat{y} = 1$ if they are the same person and $0$ if they are not.\n",
    "    * Alternative to the triplet loss \n",
    "    * This makes face recognition into a binary classificaion problem!\n",
    "    * Let's formulate $\\hat{y}$ as follows. Say you have an encoding that has $h$ features and $i$ and $j$ are 2 inputs (faces) : Then \n",
    "        * $\\hat{y} = \\sigma(\\sum\\limits_{k=1}^{h} w_i \\vert f(x^{(i)})_k - f(x^{(j)})_k \\vert + b) $\n",
    "        * Chi-square formula   \n",
    "    * precompute faces in a database so you only have to compute new images \n",
    "    * use different pairs to train the Siamese NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Style Transfer \n",
    "\n",
    "#### What is neural style transfer?\n",
    "\n",
    "* Given a content image $C$ and a style image $S$, output a generated image $G$ that is in the style of $S$ and has the contents of $C$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
