{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition \n",
    "\n",
    "#### What is face recognition? \n",
    "\n",
    "* Face verification vs. face recognition \n",
    "   * Verification - given an image and name/ID, output whether the image is the claimed person \n",
    "   * Recognition - given you have $K$ persons in a database and their respective names/IDs, when you get an input image, output ID if image is any of the $K$ persons (or \"not recognized\")\n",
    "   \n",
    "#### One Shot Learning \n",
    "\n",
    "* One-shot learning - recognize that person given just one image of that person's face\n",
    "    * aka learn from just **one** example \n",
    "    * to make it work, we learn a \"similarity\" function \n",
    "        * $d($img1, img2$)$ $=$ degree of difference between images\n",
    "            * If $d($img1,img2$) \\leq \\tau \\rightarrow$ \"same\" else \"different\"\n",
    "            * pairwise comparison between the input image and each of the $K$ persons in the database\n",
    "            \n",
    "#### Siamese Network \n",
    "\n",
    "* Taigman et. al., 2014. DeepFace closing the gap to human level performance\n",
    "* Siamese Network - running two **identical CNNs** on two different inputs \n",
    "* Siamese Network explained: Suppose you have images $x^{(1)}$ and $x^{(2)} $ such that\n",
    "    * $x^{(1)} \\rightarrow$ ConvNet until last FC layer $\\rightarrow f(x^{(1)}) =$ \"encoding of $x^{(1)}$\"\n",
    "    * $x^{(2)} \\rightarrow$ ConvNet until last FC layer $\\rightarrow f(x^{(2)}) =$ \"encoding of $x^{(2)}$\"\n",
    "    * Then, we can define $d(x^{(1)}, x^{(2)}) = \\Vert {f(x^{(1)}) -  f(x^{(2)})}\\Vert^2_2$ such that:\n",
    "        * $\\Vert {f(x^{(i)}) -  f(x^{(j)})}\\Vert^2_2$ is small if $x^{(i)}$ and  $x^{(j)}$ are the same person \n",
    "        * $\\Vert {f(x^{(i)}) -  f(x^{(j)})}\\Vert^2_2$ is large if $x^{(i)}$ and  $x^{(j)}$ are different people \n",
    "            * Use backprop until all these conditions are satisfied\n",
    "            \n",
    "#### Triplet Loss \n",
    "\n",
    "* Schroff et al. 2015, FaceNet: A unified embedding for face recognition and clustering \n",
    "* One way to learn parameters to get a good encoding for faces is to define and apply gradient descent on triplet loss function\n",
    "* Suppose $A$ = anchor image, $P$ = positive (same person), $N$ = negative (different person)\n",
    "    * Want $\\Vert f(A) - f(P)\\Vert^2 \\leq \\Vert f(A) - f(N)\\Vert^2$ \n",
    "        * Trivial solution workaround since $\\Vert f(A) - f(P)\\Vert^2 - \\Vert f(A) - f(N)\\Vert^2 \\leq 0 $ you can just make everything zero, so we add a margin $\\alpha$ such that:\n",
    "           *  $\\Vert f(A) - f(P)\\Vert^2 - \\Vert f(A) - f(N)\\Vert^2 + \\alpha \\leq 0 $\n",
    "        * Thus, we have $\\Vert f(A) - f(P)\\Vert^2 + \\alpha \\leq \\Vert f(A) - f(N)\\Vert^2$\n",
    "        \n",
    "* Triplet loss function: Given 3 images $A, P, N$:\n",
    "    * Define $ L(A,P,N) = \\max(\\Vert f(A) - f(P)\\Vert^2 - \\Vert f(A) - f(N)\\Vert^2 + \\alpha, 0)$\n",
    "    * Thus, overall cost is $J = \\sum\\limits_{i=1}^{m}{L(A^{(i)},P^{(i)},N^{(i)})}$\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
