{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "---\n",
    "\n",
    "###  Computer Vision \n",
    "* The main architecture for learning from computer vision applications is **convolutional neural networks**\n",
    "    * The main problem right now is computational cost: images can be very big/detailed which means lots of pixels which means lots of computation\n",
    "---\n",
    "\n",
    "###  Edge Detection Example \n",
    "\n",
    "* motivating example for understanding convolution operation \n",
    "* filter/kernel - object which an image will be convolved by \n",
    "    * in example, it's a column of 1s then 0s, then -1s \n",
    "* convolution process:\n",
    "    * each cell in a filter/kernel is multipled by a cell in the image until all the filter's cells have been used\n",
    "    * add up all the multiplications and put that value in an output matrix\n",
    "    * stride based on some predetermined stride value\n",
    "    * repeat\n",
    "* Ng illustrates why the filter used in the example is a vertical edge detector \n",
    "---\n",
    "\n",
    "### More Edge Detection \n",
    "* Ng continues to illustrate vertical edge detectors and then a horizontal edge detector using different filters \n",
    "* There's a debate in the literature as to what are the best numbers for filters to use\n",
    "    * Sobel filter - more weight for central region \n",
    "    * Scharr filter \n",
    "* for deep learning, maybe you don't have to hand pick the 9 numbers, but maybe **learn** them by treating each cell in the filter as a parameter to tune \n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding \n",
    "* Problems that padding can alleviate:\n",
    "   * shrinking output: $(n - f + 1)$ output image size \n",
    "   * throwing out a lot of information from the edges of the image \n",
    "* put a border, a padding around an image to perform padding \n",
    "    * thus, output image size with padding is $(n + 2p - f + 1)$\n",
    "* valid convolution - no padding i.e. output size is $n - f + 1$ \n",
    "* same convolution - output size is the same as the input size s.t. $n + 2p - f + 1 = n$\n",
    "* $f$ is usually odd, and sometimes the literature puts importance to the center of the filter/kernel \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strided Convolutions\n",
    "* stride - how many positions to move between each convolution\n",
    "* output size will then be $\\lfloor\\dfrac{n + 2p -f}{s} + 1\\rfloor$ by $\\lfloor\\dfrac{n + 2p -f}{s} + 1\\rfloor$\n",
    "* Ng mentions how AI convolution is defined a little differently from math convolution \n",
    "    * more precise to call AI convolution as the 'cross correlation' operation\n",
    "---\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutions Over Volume \n",
    "* convolution of volumes involves having filters/kernels with size (f_height, f_width, num_channels_in_input)\n",
    "    * Ng has a convolution filter example of (3 x 3 x 3)\n",
    "* The 3D filter/kernel is basically a 2D filter for each channel.\n",
    "    * Each 2D filter can have different numbers associated with it to find something you want from an image \n",
    "* To create a 3D output volume, you can have 2 or more convolutions on the same input and stack them up \n",
    "    * Ng illustrates that 2 convolutions of size (3x3x3) on a (6x6x3) image results in (4x4x2) output volume \n",
    "----\n",
    "    \n",
    "### One Layer of a Convolutional Network\n",
    "* One layer of a convolutional network is as follow: \n",
    "    * input image (convolved_by) filters $=$ convolved_matrix $\\rightarrow$ RELU(convolved_matrix + $b$) = output_matrix  \n",
    "* the parameters to tune are each cell in a filter. Ng gives an example where there are in image is convolved by 10 (3x3x3) filters which means 27 + 1 = 28 parameters for each filter x 10 filters = 280 parameters in total. \n",
    "    * One **really** good property of CNNs is that no matter how big the input size is, the parameters to tune stay constant. In this case, 280 parameters no matter if the image size is (3x3x3) or (1000x1000x3)\n",
    "\n",
    "\n",
    "* Notation of CNNs \n",
    "    * If layer $l$ is a convolution layer:\n",
    "       * $f^{[l]}$ = filter size \n",
    "       * $p^{[l]}$ = padding \n",
    "       * $s^{[l]}$ = stride \n",
    "       * $n^{[l]}_c$ = number of filters\n",
    "       * Input size: $n^{[l-1]}_H \\times n^{[l-1]}_W \\times n^{[l-1]}_C$\n",
    "       * convolved_matrix size : $n^{[l]}_H \\times n^{[l]}_W \\times n^{[l]}_C$\n",
    "           * $n^{[l]}_H = \\Bigl\\lfloor \\dfrac{n^{[l-1]}_H + 2p - f^{[l]}}{s^{[l]}} + 1 \\Bigr\\rfloor$\n",
    "           * $n^{[l]}_W = \\Bigl\\lfloor \\dfrac{n^{[l-1]}_W + 2p - f^{[l]}}{s^{[l]}} + 1 \\Bigr\\rfloor$\n",
    "           * $n^{[l]}_c$ is described above \n",
    "       * Each filter is $f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_C$\n",
    "       * Activation size $a^{[l]} = n^{[l]}_H \\times n^{[l]}_W \\times n^{[l]}_C = $ convolved_matrix size\n",
    "            * Thus, if you have $m$ examples, the size of the whole set would be $A^{[l]} = m \\times n^{[l]}_H \\times n^{[l]}_W \\times n^{[l]}_C$\n",
    "       * Weights size is $f^{[l]} \\times f^{[l]} \\times n^{[l-1]}_C \\times n^{[l]}_C$\n",
    "       * bias size is $1 \\times 1 \\times 1 \\times n^{[l]}$\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Convolutional Network Example \n",
    "* Ng walks through a convolutional network:\n",
    "    * input $\\rightarrow$ (3X3)CONV $\\rightarrow$ (5x5)CONV $\\rightarrow$ (5X5)CONV $\\rightarrow$ flatten to a vector $\\rightarrow$ logistic/softmax function $\\rightarrow \\hat{y}$\n",
    "    * general trend is that height and width gradually goes down when flowing through a network and number of channels goes up \n",
    "* Types of layers in a convolutional network:\n",
    "    * Convolution\n",
    "    * Pooling \n",
    "    * Fully connected \n",
    "----\n",
    "### Pooling Layers \n",
    "* pooling reduces the size of the representation as well as makes some of the features detected more robust \n",
    "* Ng illustrates MAXPOOLing process \n",
    "    * Take some MAXPOOL filter/window on an image, and take the max value of all the cells in that filter, and put it in the maxpooled_matrix \n",
    "* preserves features that have been found in some portion of a matrix/image \n",
    "* no parameters to learn!\n",
    "* Ng illustrates an example\n",
    "* For 3D images, do max pooling independently on each $n_c$ channels \n",
    "* AVGPOOLing also exists, but isn't used as much \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network Example \n",
    "* Ng gives an example of a CNN\n",
    "* 2 conventions\n",
    "    * treat CONV1 and POOL1 as in the same layer\n",
    "    * treat CONV1 and POOL1 as each their own layer "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
